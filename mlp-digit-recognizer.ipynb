{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"A single neuron with the sigmoid activation function.\n",
    "       Attributes:\n",
    "          inputs: The number of inputs in the perceptron, not counting the bias.\n",
    "          bias:   The bias term. By default it's 1.0.\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, bias = 1.0):\n",
    "        \"\"\"Return a new Perceptron object with the specified number of inputs (+1 for the bias).\"\"\" \n",
    "        self.weights = (np.random.rand(inputs+1) * 2) - 1 \n",
    "        self.bias = bias\n",
    "\n",
    "    def run(self, x):\n",
    "        \"\"\"Run the perceptron. x is a python list with the input values.\"\"\"\n",
    "        x_sum = np.dot(np.append(x,self.bias),self.weights)\n",
    "        return self.sigmoid(x_sum)\n",
    "\n",
    "    def set_weights(self, w_init):\n",
    "        \"\"\"Set the weights. w_init is a python list with the weights.\"\"\"\n",
    "        self.weights = np.array(w_init)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Evaluate the sigmoid function for the floating point input x.\"\"\"\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron:     \n",
    "    \"\"\"A multilayer perceptron class that uses the Perceptron class above.\n",
    "       Attributes:\n",
    "          layers:  A python list with the number of elements per layer.\n",
    "          bias:    The bias term. The same bias is used for all neurons.\n",
    "          eta:     The learning rate.\"\"\"\n",
    "\n",
    "    def __init__(self, layers, bias = 1.0, eta = 0.5):\n",
    "        \"\"\"Return a new MLP object with the specified parameters.\"\"\" \n",
    "        self.layers = np.array(layers,dtype=object)\n",
    "        self.bias = bias\n",
    "        self.eta = eta\n",
    "        self.network = [] # The list of lists of neurons\n",
    "        self.values = []  # The list of lists of output values\n",
    "        self.d = []       # The list of lists of error terms (lowercase deltas)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            self.values.append([])\n",
    "            self.d.append([])\n",
    "            self.network.append([])\n",
    "            self.values[i] = [0.0 for j in range(self.layers[i])]\n",
    "            self.d[i] = [0.0 for j in range(self.layers[i])]\n",
    "            if i > 0:      #network[0] is the input layer, so it has no neurons\n",
    "                for j in range(self.layers[i]): \n",
    "                    self.network[i].append(Perceptron(inputs = self.layers[i-1], bias = self.bias))\n",
    "        \n",
    "        self.network = np.array([np.array(x) for x in self.network],dtype=object)\n",
    "        self.values = np.array([np.array(x) for x in self.values],dtype=object)\n",
    "        self.d = np.array([np.array(x) for x in self.d],dtype=object)\n",
    "\n",
    "    def set_weights(self, w_init):\n",
    "        \"\"\"Set the weights. \n",
    "           w_init is a 3D list with the weights for all but the input layer.\"\"\"\n",
    "        for i in range(len(w_init)):\n",
    "            for j in range(len(w_init[i])):\n",
    "                self.network[i+1][j].set_weights(w_init[i][j])\n",
    "\n",
    "    def print_weights(self):\n",
    "        print()\n",
    "        for i in range(1,len(self.network)):\n",
    "            for j in range(self.layers[i]):\n",
    "                print(\"Layer\",i+1,\"Neuron\",j,self.network[i][j].weights)\n",
    "        print()\n",
    "\n",
    "    def run(self, x):\n",
    "        \"\"\"Feed a sample x into the MultiLayer Perceptron.\"\"\"\n",
    "        x = np.array(x,dtype=object)\n",
    "        self.values[0] = x\n",
    "        for i in range(1,len(self.network)):\n",
    "            for j in range(self.layers[i]):  \n",
    "                self.values[i][j] = self.network[i][j].run(self.values[i-1])\n",
    "        return self.values[-1]\n",
    "    \n",
    "    def bp(self, x, y):\n",
    "        \"\"\"Run a single (x,y) pair with the backpropagation algorithm.\"\"\"\n",
    "        x = np.array(x,dtype=object)\n",
    "        y = np.array(y,dtype=object)\n",
    "\n",
    "        # Backpropagation Step by Step:\n",
    "\n",
    "        # STEP 1: Feed a sample to the network \n",
    "        outputs = self.run(x)\n",
    "        \n",
    "        # STEP 2: Calculate the MSE\n",
    "        error = (y - outputs)\n",
    "        MSE = sum( error ** 2) / self.layers[-1]\n",
    "\n",
    "        # STEP 3: Calculate the output error terms\n",
    "        self.d[-1] = outputs * (1 - outputs) * (error)\n",
    "\n",
    "        # STEP 4: Calculate the error term of each unit on each layer\n",
    "        for i in reversed(range(1,len(self.network)-1)):\n",
    "            for h in range(len(self.network[i])):\n",
    "                fwd_error = 0.0\n",
    "                for k in range(self.layers[i+1]): \n",
    "                    fwd_error += self.network[i+1][k].weights[h] * self.d[i+1][k]               \n",
    "                self.d[i][h] = self.values[i][h] * (1-self.values[i][h]) * fwd_error\n",
    "\n",
    "        # STEPS 5 & 6: Calculate the deltas and update the weights\n",
    "        for i in range(1,len(self.network)):\n",
    "            for j in range(self.layers[i]):\n",
    "                for k in range(self.layers[i-1]+1):\n",
    "                    if k==self.layers[i-1]:\n",
    "                        delta = self.eta * self.d[i][j] * self.bias\n",
    "                    else:\n",
    "                        delta = self.eta * self.d[i][j] * self.values[i-1][k]\n",
    "                    self.network[i][j].weights[k] += delta\n",
    "        return MSE\n",
    "\n",
    "\n",
    "\n",
    "#test code\n",
    "epochs = int(input(\"How many epochs? \"))\n",
    "mlp1 = MultiLayerPerceptron(layers=[7,7,1])\n",
    "mlp2 = MultiLayerPerceptron(layers=[7,7,10])\n",
    "mlp3 = MultiLayerPerceptron(layers=[7,7,7])\n",
    "\n",
    "# Dataset for the 7 to 1 network\n",
    "print(\"Training 7 to 1 network...\")\n",
    "for i in range(epochs):\n",
    "    mse = 0.0\n",
    "    mse += mlp1.bp([1,1,1,1,1,1,0],[0.05])    #0 pattern\n",
    "    mse += mlp1.bp([0,1,1,0,0,0,0],[0.15])    #1 pattern\n",
    "    mse += mlp1.bp([1,1,0,1,1,0,1],[0.25])    #2 pattern\n",
    "    mse += mlp1.bp([1,1,1,1,0,0,1],[0.35])    #3 pattern\n",
    "    mse += mlp1.bp([0,1,1,0,0,1,1],[0.45])    #4 pattern\n",
    "    mse += mlp1.bp([1,0,1,1,0,1,1],[0.55])    #5 pattern\n",
    "    mse += mlp1.bp([1,0,1,1,1,1,1],[0.65])    #6 pattern\n",
    "    mse += mlp1.bp([1,1,1,0,0,0,0],[0.75])    #7 pattern\n",
    "    mse += mlp1.bp([1,1,1,1,1,1,1],[0.85])    #8 pattern\n",
    "    mse += mlp1.bp([1,1,1,1,0,1,1],[0.95])    #9 pattern\n",
    "    mse = mse/10.0\n",
    "\n",
    "# Dataset for the 7 to 10 network\n",
    "print(\"Training 7 to 10 network...\")\n",
    "for i in range(epochs):\n",
    "    mse = 0.0\n",
    "    mse += mlp2.bp([1,1,1,1,1,1,0],[1,0,0,0,0,0,0,0,0,0])    #0 pattern\n",
    "    mse += mlp2.bp([0,1,1,0,0,0,0],[0,1,0,0,0,0,0,0,0,0])    #1 pattern\n",
    "    mse += mlp2.bp([1,1,0,1,1,0,1],[0,0,1,0,0,0,0,0,0,0])    #2 pattern\n",
    "    mse += mlp2.bp([1,1,1,1,0,0,1],[0,0,0,1,0,0,0,0,0,0])    #3 pattern\n",
    "    mse += mlp2.bp([0,1,1,0,0,1,1],[0,0,0,0,1,0,0,0,0,0])    #4 pattern\n",
    "    mse += mlp2.bp([1,0,1,1,0,1,1],[0,0,0,0,0,1,0,0,0,0])    #5 pattern\n",
    "    mse += mlp2.bp([1,0,1,1,1,1,1],[0,0,0,0,0,0,1,0,0,0])    #6 pattern\n",
    "    mse += mlp2.bp([1,1,1,0,0,0,0],[0,0,0,0,0,0,0,1,0,0])    #7 pattern\n",
    "    mse += mlp2.bp([1,1,1,1,1,1,1],[0,0,0,0,0,0,0,0,1,0])    #8 pattern\n",
    "    mse += mlp2.bp([1,1,1,1,0,1,1],[0,0,0,0,0,0,0,0,0,1])    #9 pattern\n",
    "    mse = mse/10.0\n",
    "\n",
    "# Dataset for the 7 to 7 network\n",
    "print(\"Training 7 to 7 network...\")\n",
    "for i in range(epochs):\n",
    "    mse = 0.0\n",
    "    mse += mlp3.bp([1,1,1,1,1,1,0],[1,1,1,1,1,1,0])    #0 pattern\n",
    "    mse += mlp3.bp([0,1,1,0,0,0,0],[0,1,1,0,0,0,0])    #1 pattern\n",
    "    mse += mlp3.bp([1,1,0,1,1,0,1],[1,1,0,1,1,0,1])    #2 pattern\n",
    "    mse += mlp3.bp([1,1,1,1,0,0,1],[1,1,1,1,0,0,1])    #3 pattern\n",
    "    mse += mlp3.bp([0,1,1,0,0,1,1],[0,1,1,0,0,1,1])    #4 pattern\n",
    "    mse += mlp3.bp([1,0,1,1,0,1,1],[1,0,1,1,0,1,1])    #5 pattern\n",
    "    mse += mlp3.bp([1,0,1,1,1,1,1],[1,0,1,1,1,1,1])    #6 pattern\n",
    "    mse += mlp3.bp([1,1,1,0,0,0,0],[1,1,1,0,0,0,0])    #7 pattern\n",
    "    mse += mlp3.bp([1,1,1,1,1,1,1],[1,1,1,1,1,1,1])    #8 pattern\n",
    "    mse += mlp3.bp([1,1,1,1,0,1,1],[1,1,1,1,0,1,1])    #9 pattern\n",
    "    mse = mse/10.0\n",
    "\n",
    "print(\"Done!\\n\")\n",
    "pattern = [1.2]\n",
    "while(pattern[0]>=0.0):\n",
    "    pattern = list(map(float, input(\"Input pattern 'a b c d e f g': \").strip().split()))\n",
    "    if pattern[0]<0.0:\n",
    "        break\n",
    "    print()\n",
    "    print(\"The number recognized by the 7 to 1 network is\", \\\n",
    "        int(mlp1.run(pattern)*10))\n",
    "\n",
    "    print(\"The number recognized by the 7 to 10 network is\", \\\n",
    "        np.argmax(mlp2.run(pattern)))\n",
    "\n",
    "    print(\"The pattern recognized by the 7 to 7 network is\", \\\n",
    "        [int(x) for x in (mlp3.run(pattern) + 0.5)] ,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
